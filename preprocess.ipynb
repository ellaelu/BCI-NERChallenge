{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from scipy import signal\n",
    "import regex as reg\n",
    "from pyriemann.estimation import XdawnCovariances\n",
    "from pyriemann.tangentspace import TangentSpace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "things to do: ICA filtering to remove artifacts, butterworth filter, epoching ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv('Data/TrainLabels.csv')\n",
    "submission = pd.read_csv('Data/SampleSubmission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IdFeedBack</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>S01_Sess01_FB001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>S01_Sess01_FB002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>S01_Sess01_FB003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>S01_Sess01_FB004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>S01_Sess01_FB005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3395</td>\n",
       "      <td>S25_Sess05_FB096</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3396</td>\n",
       "      <td>S25_Sess05_FB097</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3397</td>\n",
       "      <td>S25_Sess05_FB098</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3398</td>\n",
       "      <td>S25_Sess05_FB099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3399</td>\n",
       "      <td>S25_Sess05_FB100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            IdFeedBack  Prediction\n",
       "0     S01_Sess01_FB001           0\n",
       "1     S01_Sess01_FB002           0\n",
       "2     S01_Sess01_FB003           0\n",
       "3     S01_Sess01_FB004           0\n",
       "4     S01_Sess01_FB005           0\n",
       "...                ...         ...\n",
       "3395  S25_Sess05_FB096           0\n",
       "3396  S25_Sess05_FB097           0\n",
       "3397  S25_Sess05_FB098           0\n",
       "3398  S25_Sess05_FB099           0\n",
       "3399  S25_Sess05_FB100           0\n",
       "\n",
       "[3400 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 60 feedbacks for each session, AKA, 12 5 letter words. Each feedback/letter was either a right or wrong prediction from the user. Using the EEG data, we must train a model on the tendencies within the EEG data itself, whenever a feedback was presented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IdFeedBack</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>S02_Sess01_FB001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>S02_Sess01_FB002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>S02_Sess01_FB003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>S02_Sess01_FB004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>S02_Sess01_FB005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5435</td>\n",
       "      <td>S26_Sess05_FB096</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5436</td>\n",
       "      <td>S26_Sess05_FB097</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5437</td>\n",
       "      <td>S26_Sess05_FB098</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5438</td>\n",
       "      <td>S26_Sess05_FB099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5439</td>\n",
       "      <td>S26_Sess05_FB100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5440 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            IdFeedBack  Prediction\n",
       "0     S02_Sess01_FB001           1\n",
       "1     S02_Sess01_FB002           1\n",
       "2     S02_Sess01_FB003           0\n",
       "3     S02_Sess01_FB004           0\n",
       "4     S02_Sess01_FB005           1\n",
       "...                ...         ...\n",
       "5435  S26_Sess05_FB096           1\n",
       "5436  S26_Sess05_FB097           0\n",
       "5437  S26_Sess05_FB098           0\n",
       "5438  S26_Sess05_FB099           0\n",
       "5439  S26_Sess05_FB100           1\n",
       "\n",
       "[5440 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting all the names of the training files, and then running a loop through each file, it is imported as a DataFrame, and then turned into an array, where it is appended to the training/test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data/train\\\\Data_S02_Sess01.csv',\n",
       " 'Data/train\\\\Data_S02_Sess02.csv',\n",
       " 'Data/train\\\\Data_S02_Sess03.csv',\n",
       " 'Data/train\\\\Data_S02_Sess04.csv',\n",
       " 'Data/train\\\\Data_S02_Sess05.csv',\n",
       " 'Data/train\\\\Data_S06_Sess01.csv']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_files = glob.glob('Data/train/Data*.csv')\n",
    "test_files = glob.glob('Data/test/Data*.csv')\n",
    "train_files[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_subjects = int(16)\n",
    "num_of_fb = int(340)\n",
    "freq = int(200)\n",
    "epoch_time = 1.3\n",
    "epoch = int(freq * epoch_time)\n",
    "num_of_cols = int(59)\n",
    "eeg_cols = int(56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "200*1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "extract_d(files)\n",
    "Ingest Data by looping through files\n",
    "\n",
    "Epoch 1.3 seconds after feedbackevent == 1 using epoch_d function\n",
    "\n",
    "Append values to list of arrays called temp\n",
    "\n",
    "\n",
    "Input: \n",
    "    files: array of string of file names (Data_S*_Sess*.csv)\n",
    "Output: \n",
    "    temp: final array of appended values\n",
    "'''\n",
    "def extract_d(files):\n",
    "    start = time.time()\n",
    "    \n",
    "    training_subjects = 16 #num of training subjects\n",
    "    num_of_fb = 340 #num of feedbacks / subject\n",
    "    freq = 200 #sampling rate\n",
    "    epoch_time = 1.3 #proposed epoching time in seconds\n",
    "    epoch = freq * epoch_time #epoch in indices \n",
    "    num_of_cols = int(59) \n",
    "    eeg_cols = int(56)\n",
    "    b_s = int(-0.4*freq) #index where baseline starts relative to feedback\n",
    "    b_e = int(-0.3*freq) #index where baseline ends relative to feedback\n",
    "    order = 5 #butterworth order\n",
    "    low_pass = 1 #low frequency pass for butterworth filter\n",
    "    high_pass = 40 #high frequency pass for butterworth filter\n",
    "    \n",
    "    temp = np.empty((1,260,num_of_cols), float)\n",
    "    for i, f in enumerate(files):\n",
    "        print(i,f, temp.shape)\n",
    "        df = pd.read_csv(f) #read each file\n",
    "        index_fb = df[df['FeedBackEvent'] == 1].index.values\n",
    "        df = np.array(df) \n",
    "        print(df.shape)\n",
    "        eeg = df[:,1:57] #only eeg values\n",
    "        eeg_filtered = butter_filter(order, low_pass, high_pass, freq, eeg) #butterworth filter applied\n",
    "        df[:,1:57] = eeg_filtered\n",
    "        for j, indx in enumerate(index_fb): #epoching 260 indexes (1.3 seconds) after each stimulus\n",
    "            epoch_array = df[indx:(indx+int(epoch)),:]\n",
    "            baseline_array = df[indx+b_s:indx+b_e,:] #baseline correction of 100ms (20 indexes), 400ms to 300ms before fb\n",
    "            \n",
    "            epoch_array = epoch_array.reshape((1,int(epoch),int(epoch_array.shape[1])))\n",
    "            baseline_array = baseline_array.reshape((1,20,int(baseline_array.shape[1])))\n",
    "            \n",
    "            baseline_mean = np.mean(baseline_array, axis = 1) #noise subtracted from epoched data\n",
    "            \n",
    "            epoch_array = epoch_array - baseline_mean\n",
    "            if i == 0:\n",
    "                temp = np.vstack((temp,epoch_array)) #stacking the first epoch\n",
    "            else:\n",
    "                temp = np.vstack((temp,epoch_array))\n",
    "                \n",
    "    now = time.time()\n",
    "    print('Elapsed Time: ' + str(int(now-start)) + ' seconds')\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_filter(order, low_pass, high_pass, fs,sig):\n",
    "    nyq = 0.5 * fs\n",
    "    lp = low_pass / nyq\n",
    "    hp = high_pass / nyq\n",
    "    sos = signal.butter(order, [lp, hp], btype='band', output = 'sos')\n",
    "    return signal.sosfilt(sos, sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Data/train\\Data_S02_Sess01.csv (1, 260, 59)\n",
      "(132001, 59)\n",
      "1 Data/train\\Data_S02_Sess02.csv (61, 260, 59)\n",
      "(128001, 59)\n",
      "2 Data/train\\Data_S02_Sess03.csv (121, 260, 59)\n",
      "(127001, 59)\n",
      "3 Data/train\\Data_S02_Sess04.csv (181, 260, 59)\n",
      "(128001, 59)\n",
      "4 Data/train\\Data_S02_Sess05.csv (241, 260, 59)\n",
      "(196001, 59)\n",
      "5 Data/train\\Data_S06_Sess01.csv (341, 260, 59)\n",
      "(132001, 59)\n",
      "6 Data/train\\Data_S06_Sess02.csv (401, 260, 59)\n",
      "(132601, 59)\n",
      "7 Data/train\\Data_S06_Sess03.csv (461, 260, 59)\n",
      "(132601, 59)\n",
      "8 Data/train\\Data_S06_Sess04.csv (521, 260, 59)\n",
      "(132001, 59)\n",
      "9 Data/train\\Data_S06_Sess05.csv (581, 260, 59)\n",
      "(196001, 59)\n",
      "10 Data/train\\Data_S07_Sess01.csv (681, 260, 59)\n",
      "(134401, 59)\n",
      "11 Data/train\\Data_S07_Sess02.csv (741, 260, 59)\n",
      "(136001, 59)\n",
      "12 Data/train\\Data_S07_Sess03.csv (801, 260, 59)\n",
      "(136001, 59)\n",
      "13 Data/train\\Data_S07_Sess04.csv (861, 260, 59)\n",
      "(135001, 59)\n",
      "14 Data/train\\Data_S07_Sess05.csv (921, 260, 59)\n",
      "(203001, 59)\n",
      "15 Data/train\\Data_S11_Sess01.csv (1021, 260, 59)\n",
      "(145001, 59)\n",
      "16 Data/train\\Data_S11_Sess02.csv (1081, 260, 59)\n",
      "(155001, 59)\n",
      "17 Data/train\\Data_S11_Sess03.csv (1141, 260, 59)\n",
      "(146801, 59)\n",
      "18 Data/train\\Data_S11_Sess04.csv (1201, 260, 59)\n",
      "(149001, 59)\n",
      "19 Data/train\\Data_S11_Sess05.csv (1261, 260, 59)\n",
      "(239001, 59)\n",
      "20 Data/train\\Data_S12_Sess01.csv (1361, 260, 59)\n",
      "(166001, 59)\n",
      "21 Data/train\\Data_S12_Sess02.csv (1421, 260, 59)\n",
      "(147001, 59)\n",
      "22 Data/train\\Data_S12_Sess03.csv (1481, 260, 59)\n",
      "(150001, 59)\n",
      "23 Data/train\\Data_S12_Sess04.csv (1541, 260, 59)\n",
      "(148601, 59)\n",
      "24 Data/train\\Data_S12_Sess05.csv (1601, 260, 59)\n",
      "(236601, 59)\n",
      "25 Data/train\\Data_S13_Sess01.csv (1701, 260, 59)\n",
      "(154001, 59)\n",
      "26 Data/train\\Data_S13_Sess02.csv (1761, 260, 59)\n",
      "(150201, 59)\n",
      "27 Data/train\\Data_S13_Sess03.csv (1821, 260, 59)\n",
      "(151601, 59)\n",
      "28 Data/train\\Data_S13_Sess04.csv (1881, 260, 59)\n",
      "(152001, 59)\n",
      "29 Data/train\\Data_S13_Sess05.csv (1941, 260, 59)\n",
      "(242801, 59)\n",
      "30 Data/train\\Data_S14_Sess01.csv (2041, 260, 59)\n",
      "(151001, 59)\n",
      "31 Data/train\\Data_S14_Sess02.csv (2101, 260, 59)\n",
      "(152601, 59)\n",
      "32 Data/train\\Data_S14_Sess03.csv (2161, 260, 59)\n",
      "(151801, 59)\n",
      "33 Data/train\\Data_S14_Sess04.csv (2221, 260, 59)\n",
      "(151401, 59)\n",
      "34 Data/train\\Data_S14_Sess05.csv (2281, 260, 59)\n",
      "(231801, 59)\n",
      "35 Data/train\\Data_S16_Sess01.csv (2381, 260, 59)\n",
      "(153401, 59)\n",
      "36 Data/train\\Data_S16_Sess02.csv (2441, 260, 59)\n",
      "(153401, 59)\n",
      "37 Data/train\\Data_S16_Sess03.csv (2501, 260, 59)\n",
      "(153401, 59)\n",
      "38 Data/train\\Data_S16_Sess04.csv (2561, 260, 59)\n",
      "(153401, 59)\n",
      "39 Data/train\\Data_S16_Sess05.csv (2621, 260, 59)\n",
      "(246601, 59)\n",
      "40 Data/train\\Data_S17_Sess01.csv (2721, 260, 59)\n",
      "(190001, 59)\n",
      "41 Data/train\\Data_S17_Sess02.csv (2781, 260, 59)\n",
      "(154401, 59)\n",
      "42 Data/train\\Data_S17_Sess03.csv (2841, 260, 59)\n",
      "(162601, 59)\n",
      "43 Data/train\\Data_S17_Sess04.csv (2901, 260, 59)\n",
      "(154801, 59)\n",
      "44 Data/train\\Data_S17_Sess05.csv (2961, 260, 59)\n",
      "(251401, 59)\n",
      "45 Data/train\\Data_S18_Sess01.csv (3061, 260, 59)\n",
      "(158001, 59)\n",
      "46 Data/train\\Data_S18_Sess02.csv (3121, 260, 59)\n",
      "(155401, 59)\n",
      "47 Data/train\\Data_S18_Sess03.csv (3181, 260, 59)\n",
      "(155601, 59)\n",
      "48 Data/train\\Data_S18_Sess04.csv (3241, 260, 59)\n",
      "(157401, 59)\n",
      "49 Data/train\\Data_S18_Sess05.csv (3301, 260, 59)\n",
      "(244001, 59)\n",
      "50 Data/train\\Data_S20_Sess01.csv (3401, 260, 59)\n",
      "(156401, 59)\n",
      "51 Data/train\\Data_S20_Sess02.csv (3461, 260, 59)\n",
      "(160201, 59)\n",
      "52 Data/train\\Data_S20_Sess03.csv (3521, 260, 59)\n",
      "(157401, 59)\n",
      "53 Data/train\\Data_S20_Sess04.csv (3581, 260, 59)\n",
      "(160001, 59)\n",
      "54 Data/train\\Data_S20_Sess05.csv (3641, 260, 59)\n",
      "(252601, 59)\n",
      "55 Data/train\\Data_S21_Sess01.csv (3741, 260, 59)\n",
      "(163001, 59)\n",
      "56 Data/train\\Data_S21_Sess02.csv (3801, 260, 59)\n",
      "(162401, 59)\n",
      "57 Data/train\\Data_S21_Sess03.csv (3861, 260, 59)\n",
      "(167601, 59)\n",
      "58 Data/train\\Data_S21_Sess04.csv (3921, 260, 59)\n",
      "(170001, 59)\n",
      "59 Data/train\\Data_S21_Sess05.csv (3981, 260, 59)\n",
      "(247001, 59)\n",
      "60 Data/train\\Data_S22_Sess01.csv (4081, 260, 59)\n",
      "(162801, 59)\n",
      "61 Data/train\\Data_S22_Sess02.csv (4141, 260, 59)\n",
      "(165601, 59)\n",
      "62 Data/train\\Data_S22_Sess03.csv (4201, 260, 59)\n",
      "(165201, 59)\n",
      "63 Data/train\\Data_S22_Sess04.csv (4261, 260, 59)\n",
      "(163201, 59)\n",
      "64 Data/train\\Data_S22_Sess05.csv (4321, 260, 59)\n",
      "(240401, 59)\n",
      "65 Data/train\\Data_S23_Sess01.csv (4421, 260, 59)\n",
      "(165201, 59)\n",
      "66 Data/train\\Data_S23_Sess02.csv (4481, 260, 59)\n",
      "(162201, 59)\n",
      "67 Data/train\\Data_S23_Sess03.csv (4541, 260, 59)\n",
      "(161201, 59)\n",
      "68 Data/train\\Data_S23_Sess04.csv (4601, 260, 59)\n",
      "(164001, 59)\n",
      "69 Data/train\\Data_S23_Sess05.csv (4661, 260, 59)\n",
      "(257401, 59)\n",
      "70 Data/train\\Data_S24_Sess01.csv (4761, 260, 59)\n",
      "(163001, 59)\n",
      "71 Data/train\\Data_S24_Sess02.csv (4821, 260, 59)\n",
      "(161601, 59)\n",
      "72 Data/train\\Data_S24_Sess03.csv (4881, 260, 59)\n",
      "(169001, 59)\n",
      "73 Data/train\\Data_S24_Sess04.csv (4941, 260, 59)\n",
      "(163201, 59)\n",
      "74 Data/train\\Data_S24_Sess05.csv (5001, 260, 59)\n",
      "(264401, 59)\n",
      "75 Data/train\\Data_S26_Sess01.csv (5101, 260, 59)\n",
      "(172001, 59)\n",
      "76 Data/train\\Data_S26_Sess02.csv (5161, 260, 59)\n",
      "(172001, 59)\n",
      "77 Data/train\\Data_S26_Sess03.csv (5221, 260, 59)\n",
      "(169401, 59)\n",
      "78 Data/train\\Data_S26_Sess04.csv (5281, 260, 59)\n",
      "(167601, 59)\n",
      "79 Data/train\\Data_S26_Sess05.csv (5341, 260, 59)\n",
      "(266601, 59)\n",
      "Elapsed Time: 985 seconds\n"
     ]
    }
   ],
   "source": [
    "train = extract_d(train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Data/test\\Data_S01_Sess01.csv (1, 260, 59)\n",
      "(127401, 59)\n",
      "1 Data/test\\Data_S01_Sess02.csv (61, 260, 59)\n",
      "(120801, 59)\n",
      "2 Data/test\\Data_S01_Sess03.csv (121, 260, 59)\n",
      "(120801, 59)\n",
      "3 Data/test\\Data_S01_Sess04.csv (181, 260, 59)\n",
      "(123001, 59)\n",
      "4 Data/test\\Data_S01_Sess05.csv (241, 260, 59)\n",
      "(194001, 59)\n",
      "5 Data/test\\Data_S03_Sess01.csv (341, 260, 59)\n",
      "(138001, 59)\n",
      "6 Data/test\\Data_S03_Sess02.csv (401, 260, 59)\n",
      "(131001, 59)\n",
      "7 Data/test\\Data_S03_Sess03.csv (461, 260, 59)\n",
      "(131001, 59)\n",
      "8 Data/test\\Data_S03_Sess04.csv (521, 260, 59)\n",
      "(132001, 59)\n",
      "9 Data/test\\Data_S03_Sess05.csv (581, 260, 59)\n",
      "(218001, 59)\n",
      "10 Data/test\\Data_S04_Sess01.csv (681, 260, 59)\n",
      "(128001, 59)\n",
      "11 Data/test\\Data_S04_Sess02.csv (741, 260, 59)\n",
      "(128801, 59)\n",
      "12 Data/test\\Data_S04_Sess03.csv (801, 260, 59)\n",
      "(130001, 59)\n",
      "13 Data/test\\Data_S04_Sess04.csv (861, 260, 59)\n",
      "(129001, 59)\n",
      "14 Data/test\\Data_S04_Sess05.csv (921, 260, 59)\n",
      "(193201, 59)\n",
      "15 Data/test\\Data_S05_Sess01.csv (1021, 260, 59)\n",
      "(133401, 59)\n",
      "16 Data/test\\Data_S05_Sess02.csv (1081, 260, 59)\n",
      "(131001, 59)\n",
      "17 Data/test\\Data_S05_Sess03.csv (1141, 260, 59)\n",
      "(134001, 59)\n",
      "18 Data/test\\Data_S05_Sess04.csv (1201, 260, 59)\n",
      "(132001, 59)\n",
      "19 Data/test\\Data_S05_Sess05.csv (1261, 260, 59)\n",
      "(224001, 59)\n",
      "20 Data/test\\Data_S08_Sess01.csv (1361, 260, 59)\n",
      "(141201, 59)\n",
      "21 Data/test\\Data_S08_Sess02.csv (1421, 260, 59)\n",
      "(137801, 59)\n",
      "22 Data/test\\Data_S08_Sess03.csv (1481, 260, 59)\n",
      "(138001, 59)\n",
      "23 Data/test\\Data_S08_Sess04.csv (1541, 260, 59)\n",
      "(139001, 59)\n",
      "24 Data/test\\Data_S08_Sess05.csv (1601, 260, 59)\n",
      "(217401, 59)\n",
      "25 Data/test\\Data_S09_Sess01.csv (1701, 260, 59)\n",
      "(138001, 59)\n",
      "26 Data/test\\Data_S09_Sess02.csv (1761, 260, 59)\n",
      "(142001, 59)\n",
      "27 Data/test\\Data_S09_Sess03.csv (1821, 260, 59)\n",
      "(140401, 59)\n",
      "28 Data/test\\Data_S09_Sess04.csv (1881, 260, 59)\n",
      "(140401, 59)\n",
      "29 Data/test\\Data_S09_Sess05.csv (1941, 260, 59)\n",
      "(215001, 59)\n",
      "30 Data/test\\Data_S10_Sess01.csv (2041, 260, 59)\n",
      "(141601, 59)\n",
      "31 Data/test\\Data_S10_Sess02.csv (2101, 260, 59)\n",
      "(142601, 59)\n",
      "32 Data/test\\Data_S10_Sess03.csv (2161, 260, 59)\n",
      "(144801, 59)\n",
      "33 Data/test\\Data_S10_Sess04.csv (2221, 260, 59)\n",
      "(144801, 59)\n",
      "34 Data/test\\Data_S10_Sess05.csv (2281, 260, 59)\n",
      "(215001, 59)\n",
      "35 Data/test\\Data_S15_Sess01.csv (2381, 260, 59)\n",
      "(152001, 59)\n",
      "36 Data/test\\Data_S15_Sess02.csv (2441, 260, 59)\n",
      "(151201, 59)\n",
      "37 Data/test\\Data_S15_Sess03.csv (2501, 260, 59)\n",
      "(152001, 59)\n",
      "38 Data/test\\Data_S15_Sess04.csv (2561, 260, 59)\n",
      "(153401, 59)\n",
      "39 Data/test\\Data_S15_Sess05.csv (2621, 260, 59)\n",
      "(225201, 59)\n",
      "40 Data/test\\Data_S19_Sess01.csv (2721, 260, 59)\n",
      "(158401, 59)\n",
      "41 Data/test\\Data_S19_Sess02.csv (2781, 260, 59)\n",
      "(159801, 59)\n",
      "42 Data/test\\Data_S19_Sess03.csv (2841, 260, 59)\n",
      "(157201, 59)\n",
      "43 Data/test\\Data_S19_Sess04.csv (2901, 260, 59)\n",
      "(166401, 59)\n",
      "44 Data/test\\Data_S19_Sess05.csv (2961, 260, 59)\n",
      "(251001, 59)\n",
      "45 Data/test\\Data_S25_Sess01.csv (3061, 260, 59)\n",
      "(169001, 59)\n",
      "46 Data/test\\Data_S25_Sess02.csv (3121, 260, 59)\n",
      "(167401, 59)\n",
      "47 Data/test\\Data_S25_Sess03.csv (3181, 260, 59)\n",
      "(173401, 59)\n",
      "48 Data/test\\Data_S25_Sess04.csv (3241, 260, 59)\n",
      "(169401, 59)\n",
      "49 Data/test\\Data_S25_Sess05.csv (3301, 260, 59)\n",
      "(270001, 59)\n",
      "Elapsed Time: 431 seconds\n"
     ]
    }
   ],
   "source": [
    "test = extract_d(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.save('Data/X_epochs_train(bs_bw).npy',train[1:,:,:])\n",
    "np.save('Data/X_epochs_test.npy(bs_bw)',test[1:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.load('Data/X_epochs_train.npy')\n",
    "test = np.load('Data/X_epochs_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3400, 260, 59)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = np.reshape(train, (5440, num_of_cols, epoch))\n",
    "test = np.reshape(test, (3400, num_of_cols, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5440, 59, 260)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After epoching shape of train and test data, no other preprocessing done yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5440, 59, 260)\n",
      "(3400, 59, 260)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping EOG, Time, and FeedBackEvent columns, and reshaping EEG data into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEG_train = train[:,1:57,:].reshape(5440*epoch, eeg_cols)\n",
    "EEG_test = test[:,1:57,:].reshape(3400*epoch, eeg_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1414400, 56)\n",
      "(884000, 56)\n"
     ]
    }
   ],
   "source": [
    "print(EEG_train.shape)\n",
    "print(EEG_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape back to apply XdawnCovariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filtered = EEG_train.reshape(5440, int(eeg_cols), int(epoch))\n",
    "test_filtered = EEG_test.reshape(3400, int(eeg_cols), int(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5440, 56, 260)\n",
      "(3400, 56, 260)\n"
     ]
    }
   ],
   "source": [
    "print(train_filtered.shape)\n",
    "print(test_filtered.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply 5th filter XdawnCovariance, and then tangent space to convert from reimann model to eucilidean space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = train_labels.Prediction.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "XC= XdawnCovariances(nfilter=5)\n",
    "X_train = XC.fit_transform(train_filtered, Y_train)\n",
    "X_test = XC.transform(test_filtered)\n",
    "X_train = TangentSpace(metric='riemann').fit_transform(X_train, y = Y_train)\n",
    "X_test = TangentSpace(metric='riemann').transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.3052637 , -0.03078197, -0.47191025, ...,  2.1746006 ,\n",
       "         0.08279183,  2.19204785],\n",
       "       [-0.26662873, -0.01810491, -0.47822838, ...,  2.23375307,\n",
       "         0.09457055,  2.21326101],\n",
       "       [-0.25089669, -0.05888838, -0.50475629, ...,  2.20956996,\n",
       "         0.13514079,  2.19849806],\n",
       "       ...,\n",
       "       [-0.94649855, -0.06894671, -0.084074  , ...,  2.67473811,\n",
       "         0.36364172,  2.17976418],\n",
       "       [-0.77543791, -0.01144206, -0.12651094, ...,  2.68098828,\n",
       "         0.35218516,  2.19277779],\n",
       "       [-0.85746837,  0.03984905, -0.02320009, ...,  2.69008051,\n",
       "         0.31847183,  2.23020558]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.68029903, -0.05177231,  0.08244949, ...,  1.45567708,\n",
       "         0.2645651 ,  0.02435095],\n",
       "       [ 0.45721737,  0.16505541,  0.5825956 , ...,  1.34716367,\n",
       "         0.85486182, -0.13663167],\n",
       "       [ 0.46666901, -0.14740266,  0.26084896, ...,  1.42327569,\n",
       "        -0.15015616, -1.34352809],\n",
       "       ...,\n",
       "       [-0.46727637,  0.2491673 , -1.1063111 , ...,  1.92021248,\n",
       "         1.4446069 ,  2.03622266],\n",
       "       [ 0.1490003 , -0.14054646, -0.85591812, ...,  2.14846434,\n",
       "         0.02407762,  2.46802044],\n",
       "       [-0.07702727,  0.19267916, -1.12229464, ...,  1.93536439,\n",
       "         1.1099897 ,  1.41722724]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.71421172,  0.01426299,  0.13618461, ..., 10.68567618,\n",
       "         0.31619202,  9.65583231],\n",
       "       [ 6.72126797,  0.0513897 ,  0.0909533 , ..., 10.55535183,\n",
       "         0.37926217,  9.51646688],\n",
       "       [ 6.64475402,  0.06201443,  0.186526  , ..., 10.4098938 ,\n",
       "         0.29485153,  9.41886387],\n",
       "       ...,\n",
       "       [ 4.90717174,  0.26493555,  0.47055065, ..., 11.02948111,\n",
       "         0.18070586, 10.41510942],\n",
       "       [ 4.85112995,  0.23628849,  0.4607396 , ..., 11.10800369,\n",
       "         0.17243078, 10.51230865],\n",
       "       [ 4.89261389,  0.24387666,  0.52946291, ..., 11.07268492,\n",
       "         0.16222918, 10.48461482]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.47828769, -1.06996745,  0.1476379 , ...,  0.34029365,\n",
       "         0.67616555,  0.50864833],\n",
       "       [-5.00791152, -0.20163138,  0.13796314, ...,  1.51407949,\n",
       "        -0.79294735,  0.65056717],\n",
       "       [-4.79634856,  0.26443099,  0.27299077, ..., -0.7216058 ,\n",
       "        -0.30756265,  1.68098416],\n",
       "       ...,\n",
       "       [-3.80145331,  0.51697185,  0.21389248, ...,  0.10877602,\n",
       "        -0.3098083 ,  1.80046052],\n",
       "       [-3.90641219,  0.19644335,  0.80647617, ...,  0.71042944,\n",
       "         1.21563236,  1.20049132],\n",
       "       [-3.48413773, -0.06080935,  0.06308115, ...,  0.29101443,\n",
       "        -0.09743197,  1.03960154]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (5440, 210)\n",
      "X_test shape:  (3400, 210)\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape: ', X_train.shape)\n",
    "print('X_test shape: ', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('Data/X_train_final(bs).npy',X_train)\n",
    "np.save('Data/X_test_final(bs).npy',X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
