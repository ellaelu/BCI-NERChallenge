{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from scipy import signal\n",
    "import regex as reg\n",
    "from pyriemann.estimation import XdawnCovariances\n",
    "from pyriemann.tangentspace import TangentSpace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "things to do: ICA filtering to remove artifacts, butterworth filter, epoching ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv('Data/TrainLabels.csv')\n",
    "submission = pd.read_csv('Data/SampleSubmission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IdFeedBack</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>S01_Sess01_FB001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>S01_Sess01_FB002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>S01_Sess01_FB003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>S01_Sess01_FB004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>S01_Sess01_FB005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3395</td>\n",
       "      <td>S25_Sess05_FB096</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3396</td>\n",
       "      <td>S25_Sess05_FB097</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3397</td>\n",
       "      <td>S25_Sess05_FB098</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3398</td>\n",
       "      <td>S25_Sess05_FB099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3399</td>\n",
       "      <td>S25_Sess05_FB100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            IdFeedBack  Prediction\n",
       "0     S01_Sess01_FB001           0\n",
       "1     S01_Sess01_FB002           0\n",
       "2     S01_Sess01_FB003           0\n",
       "3     S01_Sess01_FB004           0\n",
       "4     S01_Sess01_FB005           0\n",
       "...                ...         ...\n",
       "3395  S25_Sess05_FB096           0\n",
       "3396  S25_Sess05_FB097           0\n",
       "3397  S25_Sess05_FB098           0\n",
       "3398  S25_Sess05_FB099           0\n",
       "3399  S25_Sess05_FB100           0\n",
       "\n",
       "[3400 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 60 feedbacks for each session, AKA, 12 5 letter words. Each feedback/letter was either a right or wrong prediction from the user. Using the EEG data, we must train a model on the tendencies within the EEG data itself, whenever a feedback was presented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IdFeedBack</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>S02_Sess01_FB001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>S02_Sess01_FB002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>S02_Sess01_FB003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>S02_Sess01_FB004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>S02_Sess01_FB005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5435</td>\n",
       "      <td>S26_Sess05_FB096</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5436</td>\n",
       "      <td>S26_Sess05_FB097</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5437</td>\n",
       "      <td>S26_Sess05_FB098</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5438</td>\n",
       "      <td>S26_Sess05_FB099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5439</td>\n",
       "      <td>S26_Sess05_FB100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5440 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            IdFeedBack  Prediction\n",
       "0     S02_Sess01_FB001           1\n",
       "1     S02_Sess01_FB002           1\n",
       "2     S02_Sess01_FB003           0\n",
       "3     S02_Sess01_FB004           0\n",
       "4     S02_Sess01_FB005           1\n",
       "...                ...         ...\n",
       "5435  S26_Sess05_FB096           1\n",
       "5436  S26_Sess05_FB097           0\n",
       "5437  S26_Sess05_FB098           0\n",
       "5438  S26_Sess05_FB099           0\n",
       "5439  S26_Sess05_FB100           1\n",
       "\n",
       "[5440 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting all the names of the training files, and then running a loop through each file, it is imported as a DataFrame, and then turned into an array, where it is appended to the training/test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data/train\\\\Data_S02_Sess01.csv',\n",
       " 'Data/train\\\\Data_S02_Sess02.csv',\n",
       " 'Data/train\\\\Data_S02_Sess03.csv',\n",
       " 'Data/train\\\\Data_S02_Sess04.csv',\n",
       " 'Data/train\\\\Data_S02_Sess05.csv',\n",
       " 'Data/train\\\\Data_S06_Sess01.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_files = glob.glob('Data/train/Data*.csv')\n",
    "test_files = glob.glob('Data/test/Data*.csv')\n",
    "train_files[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "extract_d(files)\n",
    "Ingest Data by looping through files\n",
    "\n",
    "Epoch 1.3 seconds after feedbackevent == 1 using epoch_d function\n",
    "\n",
    "Append values to list of arrays called temp\n",
    "\n",
    "\n",
    "Input: \n",
    "    files: array of string of file names (Data_S*_Sess*.csv)\n",
    "Output: \n",
    "    temp: final array of appended values\n",
    "'''\n",
    "def extract_d(files):\n",
    "    start = time.time()\n",
    "    \n",
    "    freq = 200\n",
    "    epoch_time = 1.3\n",
    "    epoch = freq * epoch_time\n",
    "    temp = np.empty((1,260,59), float)\n",
    "    for i, f in enumerate(files):\n",
    "        print(i,f, temp.shape)\n",
    "        df = pd.read_csv(f)\n",
    "        #using regex to extract subject and session numbers\n",
    "        [(subject, session)] = reg.findall('Data/.+S(\\d\\d).+s(\\d\\d)',f)\n",
    "        #df.loc[:,'Subject'] = subject\n",
    "        #df.loc[:,'Session'] = session\n",
    "        index_fb = df[df['FeedBackEvent'] == 1].index.values\n",
    "        df = np.array(df)\n",
    "        for j, indx in enumerate(index_fb):\n",
    "            epoch_array = df[indx:(indx+int(epoch)),:]\n",
    "            #feedback_col = np.ones((epoch_array.shape[0],1)) + j\n",
    "            #epoch_array = np.append(epoch_array, feedback_col, 1)\n",
    "            #print(indx, epoch_array.shape)\n",
    "            epoch_array = epoch_array.reshape((1,int(epoch),int(epoch_array.shape[1])))\n",
    "            if i == 0:\n",
    "                temp = np.vstack((temp,epoch_array))\n",
    "                #temp[0] = epoch_array\n",
    "            else:\n",
    "                temp = np.vstack((temp,epoch_array))\n",
    "                \n",
    "    now = time.time()\n",
    "    print('Elapsed Time: ' + str(int(now-start)) + ' seconds')\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_filter(order, low_pass, high_pass, fs,sig):\n",
    "    nyq = 0.5 * fs\n",
    "    lp = low_pass / nyq\n",
    "    hp = high_pass / nyq\n",
    "    sos = signal.butter(order, [lp, hp], btype='band', output = 'sos')\n",
    "    return signal.sosfilt(sos, sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Data/train\\Data_S02_Sess01.csv (1, 260, 59)\n",
      "1 Data/train\\Data_S02_Sess02.csv (61, 260, 59)\n",
      "2 Data/train\\Data_S02_Sess03.csv (121, 260, 59)\n",
      "3 Data/train\\Data_S02_Sess04.csv (181, 260, 59)\n",
      "4 Data/train\\Data_S02_Sess05.csv (241, 260, 59)\n",
      "5 Data/train\\Data_S06_Sess01.csv (341, 260, 59)\n",
      "6 Data/train\\Data_S06_Sess02.csv (401, 260, 59)\n",
      "7 Data/train\\Data_S06_Sess03.csv (461, 260, 59)\n",
      "8 Data/train\\Data_S06_Sess04.csv (521, 260, 59)\n",
      "9 Data/train\\Data_S06_Sess05.csv (581, 260, 59)\n",
      "10 Data/train\\Data_S07_Sess01.csv (681, 260, 59)\n",
      "11 Data/train\\Data_S07_Sess02.csv (741, 260, 59)\n",
      "12 Data/train\\Data_S07_Sess03.csv (801, 260, 59)\n",
      "13 Data/train\\Data_S07_Sess04.csv (861, 260, 59)\n",
      "14 Data/train\\Data_S07_Sess05.csv (921, 260, 59)\n",
      "15 Data/train\\Data_S11_Sess01.csv (1021, 260, 59)\n",
      "16 Data/train\\Data_S11_Sess02.csv (1081, 260, 59)\n",
      "17 Data/train\\Data_S11_Sess03.csv (1141, 260, 59)\n",
      "18 Data/train\\Data_S11_Sess04.csv (1201, 260, 59)\n",
      "19 Data/train\\Data_S11_Sess05.csv (1261, 260, 59)\n",
      "20 Data/train\\Data_S12_Sess01.csv (1361, 260, 59)\n",
      "21 Data/train\\Data_S12_Sess02.csv (1421, 260, 59)\n",
      "22 Data/train\\Data_S12_Sess03.csv (1481, 260, 59)\n",
      "23 Data/train\\Data_S12_Sess04.csv (1541, 260, 59)\n",
      "24 Data/train\\Data_S12_Sess05.csv (1601, 260, 59)\n",
      "25 Data/train\\Data_S13_Sess01.csv (1701, 260, 59)\n",
      "26 Data/train\\Data_S13_Sess02.csv (1761, 260, 59)\n",
      "27 Data/train\\Data_S13_Sess03.csv (1821, 260, 59)\n",
      "28 Data/train\\Data_S13_Sess04.csv (1881, 260, 59)\n",
      "29 Data/train\\Data_S13_Sess05.csv (1941, 260, 59)\n",
      "30 Data/train\\Data_S14_Sess01.csv (2041, 260, 59)\n",
      "31 Data/train\\Data_S14_Sess02.csv (2101, 260, 59)\n",
      "32 Data/train\\Data_S14_Sess03.csv (2161, 260, 59)\n",
      "33 Data/train\\Data_S14_Sess04.csv (2221, 260, 59)\n",
      "34 Data/train\\Data_S14_Sess05.csv (2281, 260, 59)\n",
      "35 Data/train\\Data_S16_Sess01.csv (2381, 260, 59)\n",
      "36 Data/train\\Data_S16_Sess02.csv (2441, 260, 59)\n",
      "37 Data/train\\Data_S16_Sess03.csv (2501, 260, 59)\n",
      "38 Data/train\\Data_S16_Sess04.csv (2561, 260, 59)\n",
      "39 Data/train\\Data_S16_Sess05.csv (2621, 260, 59)\n",
      "40 Data/train\\Data_S17_Sess01.csv (2721, 260, 59)\n",
      "41 Data/train\\Data_S17_Sess02.csv (2781, 260, 59)\n",
      "42 Data/train\\Data_S17_Sess03.csv (2841, 260, 59)\n",
      "43 Data/train\\Data_S17_Sess04.csv (2901, 260, 59)\n",
      "44 Data/train\\Data_S17_Sess05.csv (2961, 260, 59)\n",
      "45 Data/train\\Data_S18_Sess01.csv (3061, 260, 59)\n",
      "46 Data/train\\Data_S18_Sess02.csv (3121, 260, 59)\n",
      "47 Data/train\\Data_S18_Sess03.csv (3181, 260, 59)\n",
      "48 Data/train\\Data_S18_Sess04.csv (3241, 260, 59)\n",
      "49 Data/train\\Data_S18_Sess05.csv (3301, 260, 59)\n",
      "50 Data/train\\Data_S20_Sess01.csv (3401, 260, 59)\n",
      "51 Data/train\\Data_S20_Sess02.csv (3461, 260, 59)\n",
      "52 Data/train\\Data_S20_Sess03.csv (3521, 260, 59)\n",
      "53 Data/train\\Data_S20_Sess04.csv (3581, 260, 59)\n",
      "54 Data/train\\Data_S20_Sess05.csv (3641, 260, 59)\n",
      "55 Data/train\\Data_S21_Sess01.csv (3741, 260, 59)\n",
      "56 Data/train\\Data_S21_Sess02.csv (3801, 260, 59)\n",
      "57 Data/train\\Data_S21_Sess03.csv (3861, 260, 59)\n",
      "58 Data/train\\Data_S21_Sess04.csv (3921, 260, 59)\n",
      "59 Data/train\\Data_S21_Sess05.csv (3981, 260, 59)\n",
      "60 Data/train\\Data_S22_Sess01.csv (4081, 260, 59)\n",
      "61 Data/train\\Data_S22_Sess02.csv (4141, 260, 59)\n",
      "62 Data/train\\Data_S22_Sess03.csv (4201, 260, 59)\n",
      "63 Data/train\\Data_S22_Sess04.csv (4261, 260, 59)\n",
      "64 Data/train\\Data_S22_Sess05.csv (4321, 260, 59)\n",
      "65 Data/train\\Data_S23_Sess01.csv (4421, 260, 59)\n",
      "66 Data/train\\Data_S23_Sess02.csv (4481, 260, 59)\n",
      "67 Data/train\\Data_S23_Sess03.csv (4541, 260, 59)\n",
      "68 Data/train\\Data_S23_Sess04.csv (4601, 260, 59)\n",
      "69 Data/train\\Data_S23_Sess05.csv (4661, 260, 59)\n",
      "70 Data/train\\Data_S24_Sess01.csv (4761, 260, 59)\n",
      "71 Data/train\\Data_S24_Sess02.csv (4821, 260, 59)\n",
      "72 Data/train\\Data_S24_Sess03.csv (4881, 260, 59)\n",
      "73 Data/train\\Data_S24_Sess04.csv (4941, 260, 59)\n",
      "74 Data/train\\Data_S24_Sess05.csv (5001, 260, 59)\n",
      "75 Data/train\\Data_S26_Sess01.csv (5101, 260, 59)\n",
      "76 Data/train\\Data_S26_Sess02.csv (5161, 260, 59)\n",
      "77 Data/train\\Data_S26_Sess03.csv (5221, 260, 59)\n",
      "78 Data/train\\Data_S26_Sess04.csv (5281, 260, 59)\n",
      "79 Data/train\\Data_S26_Sess05.csv (5341, 260, 59)\n",
      "Elapsed Time: 1036 seconds\n"
     ]
    }
   ],
   "source": [
    "train = extract_d(train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Data/test\\Data_S01_Sess01.csv (1, 260, 59)\n",
      "1 Data/test\\Data_S01_Sess02.csv (61, 260, 59)\n",
      "2 Data/test\\Data_S01_Sess03.csv (121, 260, 59)\n",
      "3 Data/test\\Data_S01_Sess04.csv (181, 260, 59)\n",
      "4 Data/test\\Data_S01_Sess05.csv (241, 260, 59)\n",
      "5 Data/test\\Data_S03_Sess01.csv (341, 260, 59)\n",
      "6 Data/test\\Data_S03_Sess02.csv (401, 260, 59)\n",
      "7 Data/test\\Data_S03_Sess03.csv (461, 260, 59)\n",
      "8 Data/test\\Data_S03_Sess04.csv (521, 260, 59)\n",
      "9 Data/test\\Data_S03_Sess05.csv (581, 260, 59)\n",
      "10 Data/test\\Data_S04_Sess01.csv (681, 260, 59)\n",
      "11 Data/test\\Data_S04_Sess02.csv (741, 260, 59)\n",
      "12 Data/test\\Data_S04_Sess03.csv (801, 260, 59)\n",
      "13 Data/test\\Data_S04_Sess04.csv (861, 260, 59)\n",
      "14 Data/test\\Data_S04_Sess05.csv (921, 260, 59)\n",
      "15 Data/test\\Data_S05_Sess01.csv (1021, 260, 59)\n",
      "16 Data/test\\Data_S05_Sess02.csv (1081, 260, 59)\n",
      "17 Data/test\\Data_S05_Sess03.csv (1141, 260, 59)\n",
      "18 Data/test\\Data_S05_Sess04.csv (1201, 260, 59)\n",
      "19 Data/test\\Data_S05_Sess05.csv (1261, 260, 59)\n",
      "20 Data/test\\Data_S08_Sess01.csv (1361, 260, 59)\n",
      "21 Data/test\\Data_S08_Sess02.csv (1421, 260, 59)\n",
      "22 Data/test\\Data_S08_Sess03.csv (1481, 260, 59)\n",
      "23 Data/test\\Data_S08_Sess04.csv (1541, 260, 59)\n",
      "24 Data/test\\Data_S08_Sess05.csv (1601, 260, 59)\n",
      "25 Data/test\\Data_S09_Sess01.csv (1701, 260, 59)\n",
      "26 Data/test\\Data_S09_Sess02.csv (1761, 260, 59)\n",
      "27 Data/test\\Data_S09_Sess03.csv (1821, 260, 59)\n",
      "28 Data/test\\Data_S09_Sess04.csv (1881, 260, 59)\n",
      "29 Data/test\\Data_S09_Sess05.csv (1941, 260, 59)\n",
      "30 Data/test\\Data_S10_Sess01.csv (2041, 260, 59)\n",
      "31 Data/test\\Data_S10_Sess02.csv (2101, 260, 59)\n",
      "32 Data/test\\Data_S10_Sess03.csv (2161, 260, 59)\n",
      "33 Data/test\\Data_S10_Sess04.csv (2221, 260, 59)\n",
      "34 Data/test\\Data_S10_Sess05.csv (2281, 260, 59)\n",
      "35 Data/test\\Data_S15_Sess01.csv (2381, 260, 59)\n",
      "36 Data/test\\Data_S15_Sess02.csv (2441, 260, 59)\n",
      "37 Data/test\\Data_S15_Sess03.csv (2501, 260, 59)\n",
      "38 Data/test\\Data_S15_Sess04.csv (2561, 260, 59)\n",
      "39 Data/test\\Data_S15_Sess05.csv (2621, 260, 59)\n",
      "40 Data/test\\Data_S19_Sess01.csv (2721, 260, 59)\n",
      "41 Data/test\\Data_S19_Sess02.csv (2781, 260, 59)\n",
      "42 Data/test\\Data_S19_Sess03.csv (2841, 260, 59)\n",
      "43 Data/test\\Data_S19_Sess04.csv (2901, 260, 59)\n",
      "44 Data/test\\Data_S19_Sess05.csv (2961, 260, 59)\n",
      "45 Data/test\\Data_S25_Sess01.csv (3061, 260, 59)\n",
      "46 Data/test\\Data_S25_Sess02.csv (3121, 260, 59)\n",
      "47 Data/test\\Data_S25_Sess03.csv (3181, 260, 59)\n",
      "48 Data/test\\Data_S25_Sess04.csv (3241, 260, 59)\n",
      "49 Data/test\\Data_S25_Sess05.csv (3301, 260, 59)\n",
      "Elapsed Time: 551 seconds\n"
     ]
    }
   ],
   "source": [
    "test = extract_d(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.save('Data/X_epochs_train.npy',train[1:,:,:])\n",
    "np.save('Data/X_epochs_test.npy',test[1:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.load('Data/X_epochs_train.npy')\n",
    "test = np.load('Data/X_epochs_test.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After epoching shape of train and test data, no other preprocessing done yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5440, 260, 59)\n",
      "(3400, 260, 59)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 830.677222,  979.638619,  847.257758, ...,  932.304475,\n",
       "         750.347476,  969.756009],\n",
       "       [ 882.209104, 1030.107902,  913.80757 , ..., 1000.885015,\n",
       "         828.234082, 1158.873289],\n",
       "       [ 838.759996,  984.945818,  848.060414, ...,  946.093298,\n",
       "         754.041038, 1171.585312],\n",
       "       ...,\n",
       "       [  92.333956,  193.835793,  -32.235108, ...,  252.57769 ,\n",
       "          -1.893835,  233.479999],\n",
       "       [ 153.879763,  261.568258,  115.160815, ...,  339.478242,\n",
       "          99.196563,  296.020809],\n",
       "       [  96.201981,  177.913618,   40.380734, ...,  247.905035,\n",
       "          -4.242856,  213.572852]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EEG_train.reshape(5440*260, 56)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping EOG, Time, and FeedBackEvent columns, and reshaping EEG data into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEG_train = train[:,:,1:57].reshape(5440*260, 56)\n",
    "EEG_test = test[:,:,1:57].reshape(3400*260, 56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1414400, 56)\n",
      "(884000, 56)\n"
     ]
    }
   ],
   "source": [
    "print(EEG_train.shape)\n",
    "print(EEG_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = 5\n",
    "low_pass = 1\n",
    "high_pass = 40\n",
    "fs = 200\n",
    "train_filtered = butter_filter(order, low_pass, high_pass, fs, EEG_train)\n",
    "test_filtered = butter_filter(order, low_pass, high_pass, fs, EEG_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1414400, 56)\n",
      "(884000, 56)\n"
     ]
    }
   ],
   "source": [
    "print(train_filtered.shape)\n",
    "print(test_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filtered = train_filtered.reshape(5440, 260, 56)\n",
    "test_filtered = test_filtered.reshape(3400, 260, 56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5440, 260, 56)\n",
      "(3400, 260, 56)\n"
     ]
    }
   ],
   "source": [
    "print(train_filtered.shape)\n",
    "print(test_filtered.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply 5th filter XdawnCovariance, and then tangent space to convert from reimann model to eucilidean space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = train_labels.Prediction.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "XC= XdawnCovariances(nfilter=5)\n",
    "X_train = XC.fit_transform(train_filtered, Y_train)\n",
    "X_train = TangentSpace(metric='riemann').fit_transform(X_train, y = Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = XC.transform(test_filtered)\n",
    "X_test = TangentSpace(metric='riemann').transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (5440, 210)\n",
      "X_test shape:  (3400, 210)\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape: ', X_train.shape)\n",
    "print('X_test shape: ', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('Data/X_train_final.npy',X_train)\n",
    "np.save('Data/X_test_final.npy',X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
