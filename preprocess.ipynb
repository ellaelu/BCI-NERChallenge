{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taq19\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from scipy import signal\n",
    "import regex as reg\n",
    "from pyriemann.estimation import XdawnCovariances\n",
    "from pyriemann.tangentspace import TangentSpace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv('Data/TrainLabels.csv')\n",
    "submission = pd.read_csv('Data/SampleSubmission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = train_labels.Prediction.values\n",
    "true_labels = pd.read_csv('Data/true_labels.csv', header = None)\n",
    "Y_test = true_labels[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3400,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3395</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3396</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3397</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3398</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3399</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3400 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0\n",
       "0     1\n",
       "1     1\n",
       "2     0\n",
       "3     1\n",
       "4     0\n",
       "...  ..\n",
       "3395  1\n",
       "3396  0\n",
       "3397  1\n",
       "3398  1\n",
       "3399  1\n",
       "\n",
       "[3400 rows x 1 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IdFeedBack</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>S01_Sess01_FB001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>S01_Sess01_FB002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>S01_Sess01_FB003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>S01_Sess01_FB004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>S01_Sess01_FB005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3395</td>\n",
       "      <td>S25_Sess05_FB096</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3396</td>\n",
       "      <td>S25_Sess05_FB097</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3397</td>\n",
       "      <td>S25_Sess05_FB098</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3398</td>\n",
       "      <td>S25_Sess05_FB099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3399</td>\n",
       "      <td>S25_Sess05_FB100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            IdFeedBack  Prediction\n",
       "0     S01_Sess01_FB001           0\n",
       "1     S01_Sess01_FB002           0\n",
       "2     S01_Sess01_FB003           0\n",
       "3     S01_Sess01_FB004           0\n",
       "4     S01_Sess01_FB005           0\n",
       "...                ...         ...\n",
       "3395  S25_Sess05_FB096           0\n",
       "3396  S25_Sess05_FB097           0\n",
       "3397  S25_Sess05_FB098           0\n",
       "3398  S25_Sess05_FB099           0\n",
       "3399  S25_Sess05_FB100           0\n",
       "\n",
       "[3400 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 60 feedbacks for each session, AKA, 12 5 letter words. Each feedback/letter was either a right or wrong prediction from the user. Using the EEG data, we must train a model on the tendencies within the EEG data itself, whenever a feedback was presented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IdFeedBack</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>S02_Sess01_FB001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>S02_Sess01_FB002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>S02_Sess01_FB003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>S02_Sess01_FB004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>S02_Sess01_FB005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5435</td>\n",
       "      <td>S26_Sess05_FB096</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5436</td>\n",
       "      <td>S26_Sess05_FB097</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5437</td>\n",
       "      <td>S26_Sess05_FB098</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5438</td>\n",
       "      <td>S26_Sess05_FB099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5439</td>\n",
       "      <td>S26_Sess05_FB100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5440 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            IdFeedBack  Prediction\n",
       "0     S02_Sess01_FB001           1\n",
       "1     S02_Sess01_FB002           1\n",
       "2     S02_Sess01_FB003           0\n",
       "3     S02_Sess01_FB004           0\n",
       "4     S02_Sess01_FB005           1\n",
       "...                ...         ...\n",
       "5435  S26_Sess05_FB096           1\n",
       "5436  S26_Sess05_FB097           0\n",
       "5437  S26_Sess05_FB098           0\n",
       "5438  S26_Sess05_FB099           0\n",
       "5439  S26_Sess05_FB100           1\n",
       "\n",
       "[5440 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting all the names of the training files, and then running a loop through each file, it is imported as a DataFrame, and then turned into an array, where it is appended to the training/test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data/train\\\\Data_S02_Sess01.csv',\n",
       " 'Data/train\\\\Data_S02_Sess02.csv',\n",
       " 'Data/train\\\\Data_S02_Sess03.csv',\n",
       " 'Data/train\\\\Data_S02_Sess04.csv',\n",
       " 'Data/train\\\\Data_S02_Sess05.csv',\n",
       " 'Data/train\\\\Data_S06_Sess01.csv']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_files = glob.glob('Data/train/Data*.csv')\n",
    "test_files = glob.glob('Data/test/Data*.csv')\n",
    "train_files[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_subjects = int(16)\n",
    "num_of_fb = int(340)\n",
    "freq = int(200)\n",
    "epoch_time = 1.3\n",
    "epoch = int(freq * epoch_time)\n",
    "num_of_cols = int(59)\n",
    "eeg_cols = int(56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "extract_d(files)\n",
    "Ingest Data by looping through files\n",
    "\n",
    "Epoch 1.3 seconds after feedbackevent == 1 using epoch_d function\n",
    "\n",
    "Append values to list of arrays called temp\n",
    "\n",
    "\n",
    "Input: \n",
    "    files: array of string of file names (Data_S*_Sess*.csv)\n",
    "Output: \n",
    "    temp: final array of appended values\n",
    "'''\n",
    "def extract_d(files):\n",
    "    start = time.time()\n",
    "    \n",
    "    training_subjects = 16 #num of training subjects\n",
    "    num_of_fb = 340 #num of feedbacks / subject\n",
    "    freq = 200 #sampling rate\n",
    "    epoch_time = 1.3 #proposed epoching time in seconds\n",
    "    epoch = freq * epoch_time #epoch in indices \n",
    "    num_of_cols = int(59) \n",
    "    eeg_cols = int(56)\n",
    "    b_s = int(-0.4*freq) #index where baseline starts relative to feedback (-400ms)\n",
    "    b_e = int(-0.3*freq) #index where baseline ends relative to feedback (-300ms)\n",
    "    order = 5 #butterworth order\n",
    "    low_pass = 1 #low frequency pass for butterworth filter\n",
    "    high_pass = 40 #high frequency pass for butterworth filter\n",
    "    \n",
    "    channels = ['Fp1', 'Fp2', 'AF7', 'AF3', 'AF4', 'AF8', 'F7', 'F5', 'F3', 'F1',\n",
    "       'Fz', 'F2', 'F4', 'F6', 'F8', 'FT7', 'FC5', 'FC3', 'FC1', 'FCz',\n",
    "       'FC2', 'FC4', 'FC6', 'FT8', 'T7', 'C5', 'C3', 'C1', 'Cz', 'C2',\n",
    "       'C4', 'C6', 'T8', 'TP7', 'CP5', 'CP3', 'CP1', 'CPz', 'CP2', 'CP4',\n",
    "       'CP6', 'TP8', 'P7', 'P5', 'P3', 'P1', 'Pz', 'P2', 'P4', 'P6', 'P8',\n",
    "       'PO7', 'POz', 'P08', 'O1', 'O2']\n",
    "    \n",
    "    temp = np.empty((1,len(channels), 260), float)\n",
    "    for i, f in enumerate(files):\n",
    "        print(i,f, temp.shape)\n",
    "        df = pd.read_csv(f) #read each file\n",
    "        index_fb = df[df['FeedBackEvent'] == 1].index.values\n",
    "        df_array = np.array(df) \n",
    "        \n",
    "        #uncomment below for butterworth filter\n",
    "        \n",
    "        ##Bandpass\n",
    "        eeg = df_array[:,1:57] #only eeg values to apply butterworth filter, dropping EOG, Time, and Feedback columns\n",
    "        for i, channel in enumerate(channels): # apply butterworth channel by channel\n",
    "            raw_eeg = df[channel].values\n",
    "            eeg_filtered = butter_filter(order, low_pass, high_pass, freq, raw_eeg) #butterworth filter applied\n",
    "            eeg[:,i] = eeg_filtered\n",
    "        df = np.array(df)\n",
    "        df[:,1:57] = eeg #replacing old eeg values with new ones\n",
    "        ##\n",
    "        \n",
    "        #df = np.array(df)\n",
    "        \n",
    "        for j, indx in enumerate(index_fb): #epoching 260 indexes (1.3 seconds) after each stimulus\n",
    "            epoch_array = eeg[indx:(indx+int(epoch)),:]\n",
    "            epoch_array = epoch_array.reshape((1,int(epoch_array.shape[1]), int(epoch)))\n",
    "            \n",
    "            #uncomment below for baseline correction\n",
    "            \n",
    "            ## Baseline correction\n",
    "            baseline_array = eeg[indx+b_s:indx+b_e,:] #baseline correction of 100ms (20 indexes), 400ms to 300ms before fb\n",
    "            print(baseline_array.shape)\n",
    "            baseline_mean = np.mean(baseline_array, axis = 0)\n",
    "            baseline_mean = baseline_mean.reshape((1,int(baseline_array.shape[1]), 1))\n",
    "            epoch_array = epoch_array - baseline_mean #EEG noise subtracted from epoched data\n",
    "            ##\n",
    "            \n",
    "            if i == 0:\n",
    "                temp = np.vstack((temp,epoch_array)) #stacking the first epoch\n",
    "            else:\n",
    "                temp = np.vstack((temp,epoch_array))\n",
    "    print('Final Shape:', temp.shape)\n",
    "    now = time.time()\n",
    "    print('Elapsed Time: ' + str(int(now-start)) + ' seconds')\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_filter(order, low_pass, high_pass, fs,sig):\n",
    "    nyq = 0.5 * fs\n",
    "    lp = low_pass / nyq\n",
    "    hp = high_pass / nyq\n",
    "    sos = signal.butter(order, [lp, hp], btype='band', output = 'sos')\n",
    "    return signal.sosfilt(sos, sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Data/train\\Data_S02_Sess01.csv (1, 56, 260)\n",
      "1 Data/train\\Data_S02_Sess02.csv (61, 56, 260)\n",
      "2 Data/train\\Data_S02_Sess03.csv (121, 56, 260)\n",
      "3 Data/train\\Data_S02_Sess04.csv (181, 56, 260)\n",
      "4 Data/train\\Data_S02_Sess05.csv (241, 56, 260)\n",
      "5 Data/train\\Data_S06_Sess01.csv (341, 56, 260)\n",
      "6 Data/train\\Data_S06_Sess02.csv (401, 56, 260)\n",
      "7 Data/train\\Data_S06_Sess03.csv (461, 56, 260)\n",
      "8 Data/train\\Data_S06_Sess04.csv (521, 56, 260)\n",
      "9 Data/train\\Data_S06_Sess05.csv (581, 56, 260)\n",
      "10 Data/train\\Data_S07_Sess01.csv (681, 56, 260)\n",
      "11 Data/train\\Data_S07_Sess02.csv (741, 56, 260)\n",
      "12 Data/train\\Data_S07_Sess03.csv (801, 56, 260)\n",
      "13 Data/train\\Data_S07_Sess04.csv (861, 56, 260)\n",
      "14 Data/train\\Data_S07_Sess05.csv (921, 56, 260)\n",
      "15 Data/train\\Data_S11_Sess01.csv (1021, 56, 260)\n",
      "16 Data/train\\Data_S11_Sess02.csv (1081, 56, 260)\n",
      "17 Data/train\\Data_S11_Sess03.csv (1141, 56, 260)\n",
      "18 Data/train\\Data_S11_Sess04.csv (1201, 56, 260)\n",
      "19 Data/train\\Data_S11_Sess05.csv (1261, 56, 260)\n",
      "20 Data/train\\Data_S12_Sess01.csv (1361, 56, 260)\n",
      "21 Data/train\\Data_S12_Sess02.csv (1421, 56, 260)\n",
      "22 Data/train\\Data_S12_Sess03.csv (1481, 56, 260)\n",
      "23 Data/train\\Data_S12_Sess04.csv (1541, 56, 260)\n",
      "24 Data/train\\Data_S12_Sess05.csv (1601, 56, 260)\n",
      "25 Data/train\\Data_S13_Sess01.csv (1701, 56, 260)\n",
      "26 Data/train\\Data_S13_Sess02.csv (1761, 56, 260)\n",
      "27 Data/train\\Data_S13_Sess03.csv (1821, 56, 260)\n",
      "28 Data/train\\Data_S13_Sess04.csv (1881, 56, 260)\n",
      "29 Data/train\\Data_S13_Sess05.csv (1941, 56, 260)\n",
      "30 Data/train\\Data_S14_Sess01.csv (2041, 56, 260)\n",
      "31 Data/train\\Data_S14_Sess02.csv (2101, 56, 260)\n",
      "32 Data/train\\Data_S14_Sess03.csv (2161, 56, 260)\n",
      "33 Data/train\\Data_S14_Sess04.csv (2221, 56, 260)\n",
      "34 Data/train\\Data_S14_Sess05.csv (2281, 56, 260)\n",
      "35 Data/train\\Data_S16_Sess01.csv (2381, 56, 260)\n",
      "36 Data/train\\Data_S16_Sess02.csv (2441, 56, 260)\n",
      "37 Data/train\\Data_S16_Sess03.csv (2501, 56, 260)\n",
      "38 Data/train\\Data_S16_Sess04.csv (2561, 56, 260)\n",
      "39 Data/train\\Data_S16_Sess05.csv (2621, 56, 260)\n",
      "40 Data/train\\Data_S17_Sess01.csv (2721, 56, 260)\n",
      "41 Data/train\\Data_S17_Sess02.csv (2781, 56, 260)\n",
      "42 Data/train\\Data_S17_Sess03.csv (2841, 56, 260)\n",
      "43 Data/train\\Data_S17_Sess04.csv (2901, 56, 260)\n",
      "44 Data/train\\Data_S17_Sess05.csv (2961, 56, 260)\n",
      "45 Data/train\\Data_S18_Sess01.csv (3061, 56, 260)\n",
      "46 Data/train\\Data_S18_Sess02.csv (3121, 56, 260)\n",
      "47 Data/train\\Data_S18_Sess03.csv (3181, 56, 260)\n",
      "48 Data/train\\Data_S18_Sess04.csv (3241, 56, 260)\n",
      "49 Data/train\\Data_S18_Sess05.csv (3301, 56, 260)\n",
      "50 Data/train\\Data_S20_Sess01.csv (3401, 56, 260)\n",
      "51 Data/train\\Data_S20_Sess02.csv (3461, 56, 260)\n",
      "52 Data/train\\Data_S20_Sess03.csv (3521, 56, 260)\n",
      "53 Data/train\\Data_S20_Sess04.csv (3581, 56, 260)\n",
      "54 Data/train\\Data_S20_Sess05.csv (3641, 56, 260)\n",
      "55 Data/train\\Data_S21_Sess01.csv (3741, 56, 260)\n",
      "56 Data/train\\Data_S21_Sess02.csv (3801, 56, 260)\n",
      "57 Data/train\\Data_S21_Sess03.csv (3861, 56, 260)\n",
      "58 Data/train\\Data_S21_Sess04.csv (3921, 56, 260)\n",
      "59 Data/train\\Data_S21_Sess05.csv (3981, 56, 260)\n",
      "60 Data/train\\Data_S22_Sess01.csv (4081, 56, 260)\n",
      "61 Data/train\\Data_S22_Sess02.csv (4141, 56, 260)\n",
      "62 Data/train\\Data_S22_Sess03.csv (4201, 56, 260)\n",
      "63 Data/train\\Data_S22_Sess04.csv (4261, 56, 260)\n",
      "64 Data/train\\Data_S22_Sess05.csv (4321, 56, 260)\n",
      "65 Data/train\\Data_S23_Sess01.csv (4421, 56, 260)\n",
      "66 Data/train\\Data_S23_Sess02.csv (4481, 56, 260)\n",
      "67 Data/train\\Data_S23_Sess03.csv (4541, 56, 260)\n",
      "68 Data/train\\Data_S23_Sess04.csv (4601, 56, 260)\n",
      "69 Data/train\\Data_S23_Sess05.csv (4661, 56, 260)\n",
      "70 Data/train\\Data_S24_Sess01.csv (4761, 56, 260)\n",
      "71 Data/train\\Data_S24_Sess02.csv (4821, 56, 260)\n",
      "72 Data/train\\Data_S24_Sess03.csv (4881, 56, 260)\n",
      "73 Data/train\\Data_S24_Sess04.csv (4941, 56, 260)\n",
      "74 Data/train\\Data_S24_Sess05.csv (5001, 56, 260)\n",
      "75 Data/train\\Data_S26_Sess01.csv (5101, 56, 260)\n",
      "76 Data/train\\Data_S26_Sess02.csv (5161, 56, 260)\n",
      "77 Data/train\\Data_S26_Sess03.csv (5221, 56, 260)\n",
      "78 Data/train\\Data_S26_Sess04.csv (5281, 56, 260)\n",
      "79 Data/train\\Data_S26_Sess05.csv (5341, 56, 260)\n",
      "Elapsed Time: 1034 seconds\n"
     ]
    }
   ],
   "source": [
    "train = extract_d(train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Data/test\\Data_S01_Sess01.csv (1, 56, 260)\n",
      "1 Data/test\\Data_S01_Sess02.csv (61, 56, 260)\n",
      "2 Data/test\\Data_S01_Sess03.csv (121, 56, 260)\n",
      "3 Data/test\\Data_S01_Sess04.csv (181, 56, 260)\n",
      "4 Data/test\\Data_S01_Sess05.csv (241, 56, 260)\n",
      "5 Data/test\\Data_S03_Sess01.csv (341, 56, 260)\n",
      "6 Data/test\\Data_S03_Sess02.csv (401, 56, 260)\n",
      "7 Data/test\\Data_S03_Sess03.csv (461, 56, 260)\n",
      "8 Data/test\\Data_S03_Sess04.csv (521, 56, 260)\n",
      "9 Data/test\\Data_S03_Sess05.csv (581, 56, 260)\n",
      "10 Data/test\\Data_S04_Sess01.csv (681, 56, 260)\n",
      "11 Data/test\\Data_S04_Sess02.csv (741, 56, 260)\n",
      "12 Data/test\\Data_S04_Sess03.csv (801, 56, 260)\n",
      "13 Data/test\\Data_S04_Sess04.csv (861, 56, 260)\n",
      "14 Data/test\\Data_S04_Sess05.csv (921, 56, 260)\n",
      "15 Data/test\\Data_S05_Sess01.csv (1021, 56, 260)\n",
      "16 Data/test\\Data_S05_Sess02.csv (1081, 56, 260)\n",
      "17 Data/test\\Data_S05_Sess03.csv (1141, 56, 260)\n",
      "18 Data/test\\Data_S05_Sess04.csv (1201, 56, 260)\n",
      "19 Data/test\\Data_S05_Sess05.csv (1261, 56, 260)\n",
      "20 Data/test\\Data_S08_Sess01.csv (1361, 56, 260)\n",
      "21 Data/test\\Data_S08_Sess02.csv (1421, 56, 260)\n",
      "22 Data/test\\Data_S08_Sess03.csv (1481, 56, 260)\n",
      "23 Data/test\\Data_S08_Sess04.csv (1541, 56, 260)\n",
      "24 Data/test\\Data_S08_Sess05.csv (1601, 56, 260)\n",
      "25 Data/test\\Data_S09_Sess01.csv (1701, 56, 260)\n",
      "26 Data/test\\Data_S09_Sess02.csv (1761, 56, 260)\n",
      "27 Data/test\\Data_S09_Sess03.csv (1821, 56, 260)\n",
      "28 Data/test\\Data_S09_Sess04.csv (1881, 56, 260)\n",
      "29 Data/test\\Data_S09_Sess05.csv (1941, 56, 260)\n",
      "30 Data/test\\Data_S10_Sess01.csv (2041, 56, 260)\n",
      "31 Data/test\\Data_S10_Sess02.csv (2101, 56, 260)\n",
      "32 Data/test\\Data_S10_Sess03.csv (2161, 56, 260)\n",
      "33 Data/test\\Data_S10_Sess04.csv (2221, 56, 260)\n",
      "34 Data/test\\Data_S10_Sess05.csv (2281, 56, 260)\n",
      "35 Data/test\\Data_S15_Sess01.csv (2381, 56, 260)\n",
      "36 Data/test\\Data_S15_Sess02.csv (2441, 56, 260)\n",
      "37 Data/test\\Data_S15_Sess03.csv (2501, 56, 260)\n",
      "38 Data/test\\Data_S15_Sess04.csv (2561, 56, 260)\n",
      "39 Data/test\\Data_S15_Sess05.csv (2621, 56, 260)\n",
      "40 Data/test\\Data_S19_Sess01.csv (2721, 56, 260)\n",
      "41 Data/test\\Data_S19_Sess02.csv (2781, 56, 260)\n",
      "42 Data/test\\Data_S19_Sess03.csv (2841, 56, 260)\n",
      "43 Data/test\\Data_S19_Sess04.csv (2901, 56, 260)\n",
      "44 Data/test\\Data_S19_Sess05.csv (2961, 56, 260)\n",
      "45 Data/test\\Data_S25_Sess01.csv (3061, 56, 260)\n",
      "46 Data/test\\Data_S25_Sess02.csv (3121, 56, 260)\n",
      "47 Data/test\\Data_S25_Sess03.csv (3181, 56, 260)\n",
      "48 Data/test\\Data_S25_Sess04.csv (3241, 56, 260)\n",
      "49 Data/test\\Data_S25_Sess05.csv (3301, 56, 260)\n",
      "Elapsed Time: 447 seconds\n"
     ]
    }
   ],
   "source": [
    "test = extract_d(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.save('Data/X_epochs_train(bs).npy',train[1:,:,:])\n",
    "np.save('Data/X_epochs_test(bs).npy',test[1:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.load('Data/X_epochs_train(bs).npy')\n",
    "test = np.load('Data/X_epochs_test(bs).npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5440, 56, 260)\n",
      "(3400, 56, 260)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply 5th filter XdawnCovariance, and then tangent space to convert from reimann model to eucilidean space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = train_labels.Prediction.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "XC= XdawnCovariances(nfilter=5)\n",
    "X_train = XC.fit_transform(train, Y_train)\n",
    "X_test = XC.transform(test)\n",
    "\n",
    "X_train = TangentSpace(metric='riemann').fit_transform(X_train, y = Y_train)\n",
    "X_test = TangentSpace(metric='riemann').transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.19073496, -0.07466847, -0.19129241, ..., -0.20151839,\n",
       "         0.08601067, -0.189216  ],\n",
       "       [ 0.15148   , -0.03674552,  0.01863182, ..., -0.43904765,\n",
       "        -0.04368968,  0.19220105],\n",
       "       [ 0.25723319,  0.05925857, -0.07264738, ..., -0.43044296,\n",
       "        -0.13808513, -0.38827351],\n",
       "       ...,\n",
       "       [ 0.17275684, -0.02291625, -0.0772277 , ...,  0.25046887,\n",
       "         0.04403163,  0.4463929 ],\n",
       "       [ 0.26628135,  0.002303  , -0.03140624, ...,  0.33832585,\n",
       "        -0.24549856,  0.04278776],\n",
       "       [ 0.21824943, -0.03334318,  0.04486274, ...,  0.24278182,\n",
       "        -0.04612597,  0.54603802]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.32261308, -0.14771117,  0.14257296, ...,  3.50834738,\n",
       "        -0.70118841,  3.33885254],\n",
       "       [-0.87957478, -0.22925568,  0.2134341 , ...,  3.00364927,\n",
       "        -0.12668068,  3.67561133],\n",
       "       [-0.78168907,  0.07258029, -0.14375001, ...,  4.83669489,\n",
       "         0.18522625,  5.30737553],\n",
       "       ...,\n",
       "       [-0.27090926, -0.02230058,  0.25668129, ...,  2.10703304,\n",
       "        -0.09521843,  2.17275406],\n",
       "       [-1.1621088 , -0.14258795,  0.28117237, ...,  3.34071485,\n",
       "         0.35123836,  3.05871719],\n",
       "       [-0.47244632,  0.09273379,  0.12204881, ...,  2.76882907,\n",
       "         0.36561909,  2.698652  ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (5440, 210)\n",
      "X_test shape:  (3400, 210)\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape: ', X_train.shape)\n",
    "print('X_test shape: ', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('Data/X_train_final(bs).npy',X_train)\n",
    "np.save('Data/X_test_final(bs).npy',X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
